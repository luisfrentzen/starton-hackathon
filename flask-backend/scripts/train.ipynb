{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "import pandas as pd\r\n",
    "import re\r\n",
    "import numpy as np\r\n",
    "from nltk.corpus import stopwords\r\n",
    "from nltk.stem import PorterStemmer\r\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\r\n",
    "from sklearn.pipeline import Pipeline\r\n",
    "from sklearn.metrics import classification_report, confusion_matrix\r\n",
    "from sklearn.model_selection import train_test_split\r\n",
    "from sklearn.feature_selection import SelectKBest, chi2\r\n",
    "from sqlite3 import Error\r\n",
    "from sklearn.ensemble import RandomForestClassifier\r\n",
    "from sklearn.svm import LinearSVC\r\n",
    "from sklearn.naive_bayes import MultinomialNB\r\n",
    "import os\r\n",
    "import pickle"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "data_path = '../../dataset'\r\n",
    "\r\n",
    "labels = []\r\n",
    "tokens = []\r\n",
    "\r\n",
    "titles = []\r\n",
    "\r\n",
    "for i, f in enumerate(os.listdir(data_path)):\r\n",
    "    full_path = f'{ data_path }/{ f }'\r\n",
    "    titles.append(f.split('.')[0])\r\n",
    "    \r\n",
    "    with open(full_path, 'r', encoding='utf8', errors='ignore') as infile:\r\n",
    "        for line in infile:\r\n",
    "            tokens.append(line.strip())\r\n",
    "            labels.append(i)\r\n",
    "\r\n",
    "df = pd.DataFrame(list(zip(tokens, labels)), columns=['sent', 'label'])"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "df.sample(5)"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sent</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1574</th>\n",
       "      <td>Did you know that the travel and tourism indus...</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>628</th>\n",
       "      <td>The formula weight of an ionic compound is cal...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>237</th>\n",
       "      <td>microorganism out there that can do the job. W...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>New Tissue Clearing Methods Offer a Window int...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>346</th>\n",
       "      <td>With gold moving sideways and cryptocurrencies...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   sent  label\n",
       "1574  Did you know that the travel and tourism indus...      6\n",
       "628   The formula weight of an ionic compound is cal...      2\n",
       "237   microorganism out there that can do the job. W...      0\n",
       "39    New Tissue Clearing Methods Offer a Window int...      0\n",
       "346   With gold moving sideways and cryptocurrencies...      1"
      ]
     },
     "metadata": {},
     "execution_count": 3
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "titles"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "['biotechnology',\n",
       " 'business_economics',\n",
       " 'chemical_engineering',\n",
       " 'computer_science',\n",
       " 'electrical_engineering',\n",
       " 'geography',\n",
       " 'hospitality_&_tourism',\n",
       " 'law_school',\n",
       " 'medical_school',\n",
       " 'visual_design']"
      ]
     },
     "metadata": {},
     "execution_count": 4
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "stemmer = PorterStemmer()\r\n",
    "stop_words = stopwords.words('english')\r\n",
    "\r\n",
    "df['cleaned'] = df['sent'].apply(lambda x: \" \".join([stemmer.stem(i) for i in re.sub(\"[^a-zA-Z]\", \" \", x).split() if i not in stop_words]).lower())"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "source": [
    "df.sample(5)"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sent</th>\n",
       "      <th>label</th>\n",
       "      <th>cleaned</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>405</th>\n",
       "      <td>Every day we hear about economically related p...</td>\n",
       "      <td>1</td>\n",
       "      <td>everi day hear econom relat problem global scale</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>so antibody labeling will take two days longer...</td>\n",
       "      <td>0</td>\n",
       "      <td>antibodi label take two day longer whole mous ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1001</th>\n",
       "      <td>The sooner you realize that harmonics problems...</td>\n",
       "      <td>4</td>\n",
       "      <td>the sooner realiz harmon problem rise better</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>635</th>\n",
       "      <td>A chemical equation describes what happens in ...</td>\n",
       "      <td>2</td>\n",
       "      <td>a chemic equat describ happen chemic reaction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>269</th>\n",
       "      <td>Promotions and advertising managers are respon...</td>\n",
       "      <td>1</td>\n",
       "      <td>promot advertis manag respons implement market...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   sent  label  \\\n",
       "405   Every day we hear about economically related p...      1   \n",
       "96    so antibody labeling will take two days longer...      0   \n",
       "1001  The sooner you realize that harmonics problems...      4   \n",
       "635   A chemical equation describes what happens in ...      2   \n",
       "269   Promotions and advertising managers are respon...      1   \n",
       "\n",
       "                                                cleaned  \n",
       "405    everi day hear econom relat problem global scale  \n",
       "96    antibodi label take two day longer whole mous ...  \n",
       "1001       the sooner realiz harmon problem rise better  \n",
       "635       a chemic equat describ happen chemic reaction  \n",
       "269   promot advertis manag respons implement market...  "
      ]
     },
     "metadata": {},
     "execution_count": 6
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "source": [
    "vectorizer = TfidfVectorizer(min_df= 3, stop_words=\"english\", sublinear_tf=True, norm='l2', ngram_range=(1, 2))\r\n",
    "final_features = vectorizer.fit_transform(df['cleaned']).toarray()\r\n",
    "final_features.shape"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(2504, 2413)"
      ]
     },
     "metadata": {},
     "execution_count": 7
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "source": [
    "x = df['cleaned']\r\n",
    "y = df['label']\r\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.25)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "source": [
    "v = 6\r\n",
    "cl = 'mnb'\r\n",
    "\r\n",
    "pipeline = Pipeline([('vect', vectorizer),\r\n",
    "                     ('chi',  SelectKBest(chi2, k=1700)),\r\n",
    "                     ('clf', MultinomialNB())])\r\n",
    "\r\n",
    "model = pipeline.fit(x_train, y_train)\r\n",
    "with open(f'{ cl }_model_v{ v }_c{ len(titles) }_e{ int(len(labels)/len(titles))}.pickle', 'wb') as f:\r\n",
    "    pickle.dump(model, f)\r\n",
    "\r\n",
    "ytest = np.array(y_test)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "source": [
    "print(classification_report(y_test, model.predict(x_test)))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.86      0.90        65\n",
      "           1       0.94      0.90      0.92        67\n",
      "           2       0.86      0.86      0.86        59\n",
      "           3       0.86      0.90      0.88        60\n",
      "           4       0.86      0.91      0.89        56\n",
      "           5       0.86      0.90      0.88        60\n",
      "           6       0.85      0.85      0.85        65\n",
      "           7       0.90      0.87      0.89        63\n",
      "           8       0.92      0.93      0.93        60\n",
      "           9       0.92      0.92      0.92        71\n",
      "\n",
      "    accuracy                           0.89       626\n",
      "   macro avg       0.89      0.89      0.89       626\n",
      "weighted avg       0.89      0.89      0.89       626\n",
      "\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "source": [
    "confusion_matrix(y_test, model.predict(x_test))\r\n"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([[56,  1,  3,  2,  0,  1,  0,  1,  1,  0],\n",
       "       [ 0, 60,  0,  1,  1,  1,  4,  0,  0,  0],\n",
       "       [ 1,  0, 51,  1,  3,  2,  0,  0,  0,  1],\n",
       "       [ 0,  1,  1, 54,  2,  0,  1,  1,  0,  0],\n",
       "       [ 1,  0,  1,  1, 51,  0,  0,  0,  0,  2],\n",
       "       [ 1,  1,  1,  0,  0, 54,  1,  0,  0,  2],\n",
       "       [ 0,  0,  1,  2,  2,  1, 55,  2,  1,  1],\n",
       "       [ 0,  0,  0,  1,  0,  4,  1, 55,  2,  0],\n",
       "       [ 0,  0,  1,  0,  0,  0,  3,  0, 56,  0],\n",
       "       [ 1,  1,  0,  1,  0,  0,  0,  2,  1, 65]], dtype=int64)"
      ]
     },
     "metadata": {},
     "execution_count": 20
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "source": [
    "s = \"I like to learn about biology, human bodies and cure people\""
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "source": [
    "data = [s]\r\n",
    "prep_data = []\r\n",
    "\r\n",
    "for d in data:\r\n",
    "    d = [stemmer.stem(dt).lower() for dt in d.split(' ')]\r\n",
    "    d = [dt for dt in d if dt not in stop_words]\r\n",
    "    prep_data.append(' '.join(d))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "source": [
    "prep_data"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "['like learn biology, human bodi cure peopl']"
      ]
     },
     "metadata": {},
     "execution_count": 32
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "source": [
    "res = model.predict(prep_data)\r\n",
    "lab_res = [titles[r] for r in res]\r\n",
    "\r\n",
    "for r in res:\r\n",
    "    print(titles[r])"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "medical_school\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "source": [
    "res = model.predict_proba(prep_data)\r\n",
    "\r\n",
    "print(res)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[[0.05289794 0.05144183 0.03617351 0.06150873 0.04020889 0.14514107\n",
      "  0.07093944 0.09272159 0.39733042 0.05163658]]\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.7.11",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.7.11 64-bit ('starton-hackathon': conda)"
  },
  "interpreter": {
   "hash": "75bd69696835c7cd5e8546844789fdbfaaa7569577ce0ff4a6598f8de0c37dd0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}