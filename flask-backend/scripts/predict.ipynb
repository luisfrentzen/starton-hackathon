{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 140,
   "source": [
    "import sklearn\r\n",
    "import pickle\r\n",
    "import numpy as np\r\n",
    "from nltk.corpus import stopwords\r\n",
    "from nltk.stem import PorterStemmer\r\n",
    "from nltk.tokenize import word_tokenize"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "source": [
    "stemmer = PorterStemmer()\r\n",
    "stop_words = stopwords.words('english')\r\n",
    "titles = ['biotechnology', 'business_economics', 'chemical_engineering', 'computer_science', 'electrical_engineering', 'geography', 'hospitality_&_tourism', 'law_school', 'medical_school', 'visual_design']"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "source": [
    "file = open(\"bernoulli_model_v1_c10_e230.pickle\", \"rb\")\r\n",
    "bernoulli = pickle.load(file)\r\n",
    "file.close()\r\n",
    "file = open(\"mnb_model_v1_c10_e230.pickle\", \"rb\")\r\n",
    "multinomial = pickle.load(file)\r\n",
    "file.close()\r\n",
    "file = open(\"logistic_model_v1_c10_e230.pickle\", \"rb\")\r\n",
    "logistic_regression = pickle.load(file)\r\n",
    "file.close()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "source": [
    "class VoteClassifier ():\r\n",
    "    def __init__(self, *classifiers):\r\n",
    "        self._classifiers = classifiers\r\n",
    "    \r\n",
    "    def classify(self, prep_data):\r\n",
    "        votes = [0] * len(self._classifiers[0]['clf'].classes_)\r\n",
    "        for c in self._classifiers:\r\n",
    "            v = c.predict_proba(prep_data)\r\n",
    "            votes += v\r\n",
    "        votes/=3\r\n",
    "        return votes"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "source": [
    "from nltk.corpus import wordnet\r\n",
    "def normalize_negation(text):\r\n",
    "    words = word_tokenize(text)\r\n",
    "    negation = ['not', \"n't\", \"nt\"]\r\n",
    "    document = []\r\n",
    "    i = 0\r\n",
    "    while i < len(words):\r\n",
    "        if any(string in words[i] for string in negation):\r\n",
    "            antonym_found = False\r\n",
    "            synset = wordnet.synsets(words[i+1])\r\n",
    "            for s in synset:\r\n",
    "                for synonym in s.lemmas():\r\n",
    "                    for antonym in synonym.antonyms():\r\n",
    "                        document.append(antonym.name())\r\n",
    "                        antonym_found = True\r\n",
    "                        break\r\n",
    "                    if antonym_found == True:\r\n",
    "                        break\r\n",
    "                if antonym_found == True:\r\n",
    "                    break\r\n",
    "            i+=1\r\n",
    "        else:\r\n",
    "            document.append(words[i])\r\n",
    "        i+=1\r\n",
    "    return document"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "source": [
    "s = \"i like drawing abstract painting to impress my girlfriend\""
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "source": [
    "data = [s]\r\n",
    "prep_data = []\r\n",
    "# data = normalize_negation(data)\r\n",
    "\r\n",
    "for d in data:\r\n",
    "    d = [stemmer.stem(dt).lower() for dt in d.split(' ')]\r\n",
    "    d = [dt for dt in d if dt not in stop_words]\r\n",
    "    prep_data.append(' '.join(d))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "source": [
    "prep_data"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "['want game develop']"
      ]
     },
     "metadata": {},
     "execution_count": 166
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "source": [
    "classifier = VoteClassifier(bernoulli,multinomial, logistic_regression)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "source": [
    "res = classifier.classify(prep_data)\r\n",
    "print(res)\r\n",
    "print(titles[np.argmax(res)])"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[[0.06298904 0.0454247  0.0424167  0.05292984 0.0570761  0.20710952\n",
      "  0.05010223 0.06710173 0.12930643 0.2855437 ]]\n",
      "visual_design\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "source": [
    "titles"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "['biotechnology',\n",
       " 'business_economics',\n",
       " 'chemical_engineering',\n",
       " 'computer_science',\n",
       " 'electrical_engineering',\n",
       " 'geography',\n",
       " 'hospitality_&_tourism',\n",
       " 'law_school',\n",
       " 'medical_school',\n",
       " 'visual_design']"
      ]
     },
     "metadata": {},
     "execution_count": 82
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.7.11",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.7.11  ('starton-hackathon': conda)"
  },
  "interpreter": {
   "hash": "139f7776a1e9c3660a6f664ebedf53f0b59dfff3a8fd9f1cbba96f5d98a4e405"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}